# Lint as: python3
# Copyright 2020 Google Research. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Common keras utils."""
# gtype import

from typing import Text
import tensorflow as tf
import utils


def build_batch_norm(is_training_bn: bool,
                     strategy: Text = None,
                     init_zero: bool = False,
                     data_format: Text = 'channels_last',
                     momentum: float = 0.99,
                     epsilon: float = 1e-3,
                     name: Text = 'tpu_batch_normalization'):
  """Build a batch normalization layer.

  Args:
    is_training_bn: `bool` for whether the model is training.
    strategy: `str`, whether to use tpu, horovod or other version of batch norm.
    init_zero: `bool` if True, initializes scale parameter of batch
      normalization with 0 instead of 1 (default).
    data_format: `str` either "channels_first" for `[batch, channels, height,
      width]` or "channels_last for `[batch, height, width, channels]`.
    momentum: `float`, momentume of batch norm.
    epsilon: `float`, small value for numerical stability.
    name: the name of the batch normalization layer

  Returns:
    A normalized `Tensor` with the same `data_format`.
  """
  if init_zero:
    gamma_initializer = tf.zeros_initializer()
  else:
    gamma_initializer = tf.ones_initializer()

  axis = 1 if data_format == 'channels_first' else -1
  batch_norm_class = utils.batch_norm_class(is_training_bn, strategy)
  bn_layer = batch_norm_class(axis=axis,
                              momentum=momentum,
                              epsilon=epsilon,
                              center=True,
                              scale=True,
                              gamma_initializer=gamma_initializer,
                              name=name)

  return bn_layer


def load_weights(model: tf.keras.Model, filepath: str):
  """load weights from checkpoints or keras weights"""
  if (filepath.endswith('.h5') or filepath.endswith('.keras') or
      filepath.endswith('.hdf5')):
    model.load_weights(filepath)
  else:
    ckpt = tf.train.load_checkpoint(filepath)
    for var in model.variables:
      var.assign(ckpt.get_tensor(var.name.split(':')[0]))
